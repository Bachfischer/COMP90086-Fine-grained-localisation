{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageSimilarity.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACBOPThLAqQW"
      },
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUny_OP3NTpr"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    device = \"cpu\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8B4Z7XnB0lr",
        "outputId": "f2b74166-37dd-4671-bb38-37e4135b6730"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHLp1kT1Atbd"
      },
      "source": [
        "# SOURCE: https://medium.com/pytorch/image-similarity-search-in-pytorch-1a744cf3469\n",
        "# Dataset class converting all images in the train/test folder to PyTorch dataset\n",
        "class FolderDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Creates a PyTorch dataset from folder, returning two tensor images.\n",
        "    Parameters: \n",
        "    main_dir : directory where images are stored.\n",
        "    transform (optional) : torchvision transforms to be applied while making dataset\n",
        "    Return: two images, one as input to the model and another image to compare with the original image for reconstruction.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, main_dir, transform=None):\n",
        "        self.main_dir = main_dir\n",
        "        self.transform = transform\n",
        "        self.all_imgs = os.listdir(main_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_loc = os.path.join(self.main_dir, self.all_imgs[idx])\n",
        "        image = Image.open(img_loc).convert(\"RGB\")   # our image size is (680, 490)\n",
        "        scale = T.Compose([T.Scale((512,512))])\n",
        "        image = scale(image)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            tensor_image = self.transform(image)\n",
        "\n",
        "        return tensor_image, tensor_image\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mne87Pr9A7E7"
      },
      "source": [
        "# The encoder model is a repetition of convolutional, relu and maxpool layers\n",
        "# Converts our input image to a feature representation of size (1, 256, 16, 16).\n",
        "class ConvEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple Convolutional Encoder Model\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, (3, 3), padding=(1, 1))\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.maxpool1 = nn.MaxPool2d((2, 2))\n",
        "\n",
        "        self.conv2 = nn.Conv2d(16, 32, (3, 3), padding=(1, 1))\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.maxpool2 = nn.MaxPool2d((2, 2))\n",
        "\n",
        "        self.conv3 = nn.Conv2d(32, 64, (3, 3), padding=(1, 1))\n",
        "        self.relu3 = nn.ReLU(inplace=True)\n",
        "        self.maxpool3 = nn.MaxPool2d((2, 2))\n",
        "\n",
        "        self.conv4 = nn.Conv2d(64, 128, (3, 3), padding=(1, 1))\n",
        "        self.relu4 = nn.ReLU(inplace=True)\n",
        "        self.maxpool4 = nn.MaxPool2d((2, 2))\n",
        "\n",
        "        self.conv5 = nn.Conv2d(128, 256, (3, 3), padding=(1, 1))\n",
        "        self.relu5 = nn.ReLU(inplace=True)\n",
        "        self.maxpool5 = nn.MaxPool2d((2, 2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Downscale the image with conv maxpool etc.\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.maxpool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.maxpool3(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.relu4(x)\n",
        "        x = self.maxpool4(x)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = self.relu5(x)\n",
        "        x = self.maxpool5(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC5TQICnBB6T"
      },
      "source": [
        "class ConvDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple Convolutional Decoder Model\n",
        "    Decoder takes an input of feature representations and reconstructs back the image.\n",
        "    Upscale the feature representations to the original image using transposed convolution layers of kernel size (2, 2) and stride (2, 2)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.deconv1 = nn.ConvTranspose2d(256, 128, (2, 2), stride=(2, 2))\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.deconv2 = nn.ConvTranspose2d(128, 64, (2, 2), stride=(2, 2))\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.deconv3 = nn.ConvTranspose2d(64, 32, (2, 2), stride=(2, 2))\n",
        "        self.relu3 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.deconv4 = nn.ConvTranspose2d(32, 16, (2, 2), stride=(2, 2))\n",
        "        self.relu4 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.deconv5 = nn.ConvTranspose2d(16, 3, (2, 2), stride=(2, 2))\n",
        "        self.relu5 = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "         # Upscale the image with convtranspose etc.\n",
        "        x = self.deconv1(x)\n",
        "        x = self.relu1(x)\n",
        "\n",
        "        x = self.deconv2(x)\n",
        "        x = self.relu2(x)\n",
        "\n",
        "        x = self.deconv3(x)\n",
        "        x = self.relu3(x)\n",
        "\n",
        "        x = self.deconv4(x)\n",
        "        x = self.relu4(x)\n",
        "\n",
        "        x = self.deconv5(x)\n",
        "        x = self.relu5(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PPVW9isMakl"
      },
      "source": [
        "def train_step(encoder, decoder, train_loader, loss_fn, optimizer, device):\n",
        "    \"\"\"\n",
        "    Performs a single training step\n",
        "    Args:\n",
        "    encoder: A convolutional Encoder. E.g. torch_model ConvEncoder\n",
        "    decoder: A convolutional Decoder. E.g. torch_model ConvDecoder\n",
        "    train_loader: PyTorch dataloader, containing (images, images).\n",
        "    loss_fn: PyTorch loss_fn, computes loss between 2 images.\n",
        "    optimizer: PyTorch optimizer.\n",
        "    device: \"cuda\" or \"cpu\"\n",
        "    Returns: Train Loss\n",
        "    \"\"\"\n",
        "    #  Set networks to train mode.\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "\n",
        "    for batch_idx, (train_img, target_img) in enumerate(train_loader):\n",
        "        # Move images to device\n",
        "        train_img = train_img.to(device)\n",
        "        target_img = target_img.to(device)\n",
        "        \n",
        "        # Zero grad the optimizer\n",
        "        optimizer.zero_grad()\n",
        "        # Feed the train images to encoder\n",
        "        enc_output = encoder(train_img)\n",
        "        # The output of encoder is input to decoder !\n",
        "        dec_output = decoder(enc_output)\n",
        "        \n",
        "        # Decoder output is reconstructed image\n",
        "        # Compute loss with it and orginal image which is target image.\n",
        "        loss = loss_fn(dec_output, target_img)\n",
        "        # Backpropogate\n",
        "        loss.backward()\n",
        "        # Apply the optimizer to network by calling step.\n",
        "        optimizer.step()\n",
        "    # Return the loss\n",
        "    return loss.item()\n",
        "\n",
        "def val_step(encoder, decoder, val_loader, loss_fn, device):\n",
        "    \"\"\"\n",
        "    Performs a single training step\n",
        "    Args:\n",
        "    encoder: A convolutional Encoder. E.g. torch_model ConvEncoder\n",
        "    decoder: A convolutional Decoder. E.g. torch_model ConvDecoder\n",
        "    val_loader: PyTorch dataloader, containing (images, images).\n",
        "    loss_fn: PyTorch loss_fn, computes loss between 2 images.\n",
        "    device: \"cuda\" or \"cpu\"\n",
        "    Returns: Validation Loss\n",
        "    \"\"\"\n",
        "    \n",
        "    # Set to eval mode.\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    \n",
        "    # We don't need to compute gradients while validating.\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (train_img, target_img) in enumerate(val_loader):\n",
        "            # Move to device\n",
        "            train_img = train_img.to(device)\n",
        "            target_img = target_img.to(device)\n",
        "\n",
        "            # Again as train. Feed encoder the train image.\n",
        "            enc_output = encoder(train_img)\n",
        "            # Decoder takes encoder output and reconstructs the image.\n",
        "            dec_output = decoder(enc_output)\n",
        "\n",
        "            # Validation loss for encoder and decoder.\n",
        "            loss = loss_fn(dec_output, target_img)\n",
        "    # Return the loss\n",
        "    return loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wkz1ZgfUvUvX"
      },
      "source": [
        "def create_embedding(encoder, full_loader, embedding_dim, device):\n",
        "    \"\"\"\n",
        "    Creates embedding using encoder from dataloader.\n",
        "    encoder: A convolutional Encoder. E.g. torch_model ConvEncoder\n",
        "    full_loader: PyTorch dataloader, containing (images, images) over entire dataset.\n",
        "    embedding_dim: Tuple (c, h, w) Dimension of embedding = output of encoder dimesntions.\n",
        "    device: \"cuda\" or \"cpu\"\n",
        "    Returns: Embedding of size (num_images_in_loader + 1, c, h, w)\n",
        "    \"\"\"\n",
        "    # Set encoder to eval mode.\n",
        "    encoder.eval()\n",
        "    # Just a place holder for our 0th image embedding.\n",
        "    embedding = torch.randn(embedding_dim)\n",
        "    \n",
        "    # Again we do not compute loss here so. No gradients.\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (train_img, target_img) in enumerate(full_loader):\n",
        "            # We can compute this on GPU. be faster\n",
        "            train_img = train_img.to(device)\n",
        "            \n",
        "            # Get encoder outputs and move outputs to cpu\n",
        "            enc_output = encoder(train_img).cpu()\n",
        "            # Keep adding these outputs to embeddings.\n",
        "            embedding = torch.cat((embedding, enc_output), 0)\n",
        "    \n",
        "    # Return the embeddings\n",
        "    return embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk3qPMRYBIWL",
        "outputId": "aae8d213-db6d-4e06-bb45-ab3dd02460d0"
      },
      "source": [
        "# Create the PyTorch `dataset` and the `dataloaders`\n",
        "transforms = T.Compose([T.ToTensor()]) # Normalize the pixels and convert to tensor\n",
        "# Create folder dataset\n",
        "full_dataset = FolderDataset(\"/content/drive/MyDrive/train\", transforms) \n",
        "\n",
        "train_size = int(0.75 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "\n",
        "# Split data to train and test\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# Create the train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "# Create the validation dataloader\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "# Create the full dataloader\n",
        "full_loader = torch.utils.data.DataLoader(full_dataset, batch_size=32)\n",
        "\n",
        "# Mean squared lossto compute difference between two images\n",
        "encoder = ConvEncoder() \n",
        "decoder = ConvDecoder()\n",
        "device = \"cuda\" \n",
        "max_loss = 9999\n",
        "\n",
        "# Shift models to GPU\n",
        "encoder.to(device)\n",
        "decoder.to(device)\n",
        "\n",
        "# The enocder and decoder parameters\n",
        "print(encoder.parameters())\n",
        "autoencoder_params = list(encoder.parameters()) + list(decoder.parameters())\n",
        "# Adam Optimizer\n",
        "optimizer = optim.AdamW(autoencoder_params, lr=1e-3)\n",
        "\n",
        "\n",
        "total_epochs = 10\n",
        "# Got these values from the encoder\n",
        "embedding_shape = (1, 256, 16, 16)\n",
        "\n",
        "for epoch in tqdm(range(total_epochs)):\n",
        "        train_loss = train_step(encoder, decoder, train_loader, nn.MSELoss(), optimizer, device=device)   \n",
        "        print(f\"Epochs = {epoch}, Training Loss : {train_loss}\")\n",
        "        val_loss = val_step(encoder, decoder, val_loader, nn.MSELoss(), device=device)   \n",
        "        print(f\"Epochs = {epoch}, Validation Loss : {val_loss}\")\n",
        "        # Simple Best Model saving\n",
        "        if val_loss < max_loss:\n",
        "            print(\"Validation Loss decreased, saving new best model\")\n",
        "            torch.save(encoder.state_dict(), \"encoder_model.pt\")\n",
        "            torch.save(decoder.state_dict(), \"decoder_model.pt\")\n",
        "\n",
        "# We need feature representations for the complete dataset as well (i.e full_loader)\n",
        "embedding = create_embedding(encoder, full_loader, embedding_shape, device)\n",
        "# Convert embedding to numpy and save them\n",
        "numpy_embedding = embedding.cpu().detach().numpy()\n",
        "print('numpy_embedding:', numpy_embedding)\n",
        "num_images = numpy_embedding.shape[0]\n",
        "\n",
        "# Save the embeddings for complete dataset, not just train\n",
        "flattened_embedding = numpy_embedding.reshape((num_images, -1))\n",
        "np.save(\"data_embedding.npy\", flattened_embedding)            \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object Module.parameters at 0x7f1c45c293d0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:310: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs = 0, Training Loss : 0.009722529910504818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [02:04<18:38, 124.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs = 0, Validation Loss : 0.011058343574404716\n",
            "Validation Loss decreased, saving new best model\n",
            "Epochs = 1, Training Loss : 0.006044135894626379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [04:08<16:35, 124.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs = 1, Validation Loss : 0.006075538229197264\n",
            "Validation Loss decreased, saving new best model\n",
            "Epochs = 2, Training Loss : 0.003948246594518423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [06:14<14:36, 125.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs = 2, Validation Loss : 0.004409089684486389\n",
            "Validation Loss decreased, saving new best model\n",
            "Epochs = 3, Training Loss : 0.0043773651123046875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [08:19<12:30, 125.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs = 3, Validation Loss : 0.0039024578873068094\n",
            "Validation Loss decreased, saving new best model\n",
            "Epochs = 4, Training Loss : 0.004546602256596088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [10:27<10:29, 125.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs = 4, Validation Loss : 0.00370001420378685\n",
            "Validation Loss decreased, saving new best model\n",
            "Epochs = 5, Training Loss : 0.003492643591016531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [12:33<08:23, 125.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs = 5, Validation Loss : 0.0034036722499877214\n",
            "Validation Loss decreased, saving new best model\n",
            "Epochs = 6, Training Loss : 0.00336197461001575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [14:38<06:17, 125.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs = 6, Validation Loss : 0.00344817410223186\n",
            "Validation Loss decreased, saving new best model\n",
            "Epochs = 7, Training Loss : 0.0031349333003163338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [16:42<04:10, 125.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs = 7, Validation Loss : 0.003134028520435095\n",
            "Validation Loss decreased, saving new best model\n",
            "Epochs = 8, Training Loss : 0.003520687110722065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [18:47<02:04, 124.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs = 8, Validation Loss : 0.003042994998395443\n",
            "Validation Loss decreased, saving new best model\n",
            "Epochs = 9, Training Loss : 0.002975636627525091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [20:54<00:00, 125.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs = 9, Validation Loss : 0.0029887717682868242\n",
            "Validation Loss decreased, saving new best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy_embedding: [[[[ 4.29379463e-01  1.40495654e-02  2.50384808e-01 ...  9.99481320e-01\n",
            "     5.47401547e-01 -1.71330646e-01]\n",
            "   [ 2.97027171e-01  7.69898415e-01  1.25629759e+00 ... -2.96386391e-01\n",
            "    -7.68322885e-01  1.28212422e-01]\n",
            "   [ 1.58863950e+00 -4.80478734e-01  1.36131505e-02 ... -1.55936193e+00\n",
            "     1.41450238e+00  3.18982363e-01]\n",
            "   ...\n",
            "   [ 3.66349757e-01 -1.06628311e+00 -2.82197855e-02 ...  1.83258593e-01\n",
            "     4.16724354e-01 -2.80501151e+00]\n",
            "   [-1.02106023e+00 -1.37051141e+00  1.56487370e+00 ...  6.20287120e-01\n",
            "     9.01270330e-01  5.23280978e-01]\n",
            "   [-3.26249689e-01  3.15327734e-01  1.63362160e-01 ...  4.14147750e-02\n",
            "    -3.16214785e-02 -1.24172473e+00]]\n",
            "\n",
            "  [[ 9.33707356e-01 -6.91357329e-02  3.76285911e-01 ...  1.20830953e+00\n",
            "    -1.00412741e-02 -2.35696936e+00]\n",
            "   [-6.22728884e-01  2.32567251e-01  7.16500878e-01 ... -1.87769282e+00\n",
            "    -5.18301308e-01  2.15433594e-02]\n",
            "   [ 3.70566934e-01  9.41954494e-01 -1.45646110e-01 ...  8.10753822e-01\n",
            "    -1.64592242e+00 -2.82931775e-01]\n",
            "   ...\n",
            "   [-1.34963405e+00  1.57155648e-01  1.73857123e-01 ... -4.98402566e-01\n",
            "     1.05225241e+00 -5.24690211e-01]\n",
            "   [-6.29098594e-01  6.25129402e-01  5.37209213e-01 ... -1.46099102e+00\n",
            "     1.23539877e+00 -4.81399372e-02]\n",
            "   [-7.53664255e-01  4.37530018e-02  1.23180914e+00 ...  3.85845393e-01\n",
            "    -2.30293322e+00 -2.35582337e-01]]\n",
            "\n",
            "  [[ 1.02495801e+00 -2.10631683e-01  2.71837294e-01 ... -1.09921658e+00\n",
            "     1.10475266e+00  1.63573354e-01]\n",
            "   [-1.27855107e-01 -6.07585311e-01 -1.40083206e+00 ... -9.06225502e-01\n",
            "     3.00318718e-01 -6.66932836e-02]\n",
            "   [ 3.71210337e-01 -1.56507120e-01 -1.66611516e+00 ... -6.72102720e-02\n",
            "    -2.83407032e-01 -1.03268705e-01]\n",
            "   ...\n",
            "   [ 2.54413337e-01 -1.47348985e-01  2.04875898e+00 ...  7.50299692e-01\n",
            "    -4.77105290e-01  6.72811925e-01]\n",
            "   [ 7.51505792e-01  3.13757807e-01  2.34158382e-01 ... -1.80317056e+00\n",
            "    -1.17282164e+00  2.61757398e+00]\n",
            "   [ 3.49628597e-01  2.65313119e-01  1.34240448e-01 ...  6.48100674e-01\n",
            "    -2.69393861e-01  4.14206296e-01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-8.57480049e-01 -1.28601626e-01  4.28567350e-01 ... -4.53627676e-01\n",
            "     1.27759010e-01 -6.74972236e-01]\n",
            "   [ 2.74707532e+00  7.06488609e-01  1.71641755e+00 ... -6.47096634e-01\n",
            "    -1.06744671e+00 -1.64095950e+00]\n",
            "   [ 2.08164677e-01  1.13974643e+00  6.85359478e-01 ...  3.78751069e-01\n",
            "     8.96439075e-01  4.35708076e-01]\n",
            "   ...\n",
            "   [ 2.32068777e-01 -2.94794589e-01 -1.85188556e+00 ... -7.01561272e-01\n",
            "     5.53348660e-01 -1.39966667e-01]\n",
            "   [ 2.64877528e-02  1.51158059e+00 -2.98556566e+00 ... -3.71004790e-01\n",
            "    -3.29968721e-01 -9.54111218e-01]\n",
            "   [ 1.84489989e+00  2.43176675e+00  2.17179403e-01 ...  1.47665724e-01\n",
            "     1.01044273e+00 -5.96381366e-01]]\n",
            "\n",
            "  [[-2.01998711e+00 -1.13659394e+00 -1.51274765e+00 ...  1.28253102e+00\n",
            "    -1.52578580e+00 -7.66596138e-01]\n",
            "   [ 2.53570881e-02 -1.20207429e+00  1.37325215e+00 ...  2.73230374e-01\n",
            "    -1.46566465e-01  1.76476300e-01]\n",
            "   [ 1.26664594e-01 -1.39170027e+00 -9.34358060e-01 ... -6.72731459e-01\n",
            "    -7.94653594e-01 -1.33516300e+00]\n",
            "   ...\n",
            "   [ 1.16506732e+00  1.25128841e+00  1.19010162e+00 ... -8.07642043e-01\n",
            "     1.20294321e+00 -1.92680076e-01]\n",
            "   [-5.65179348e-01  1.03169298e+00  4.59857732e-01 ... -8.95199239e-01\n",
            "    -1.54784882e+00  8.18480313e-01]\n",
            "   [-8.69491816e-01 -9.43453908e-02  5.31758070e-01 ...  8.65236342e-01\n",
            "     8.55946913e-03 -1.74791858e-01]]\n",
            "\n",
            "  [[ 1.02529657e+00 -3.64485592e-01 -9.90987718e-01 ...  1.21590102e+00\n",
            "     2.27489352e+00  1.51952636e+00]\n",
            "   [-2.05202293e+00  3.71108800e-01  4.20918852e-01 ...  1.15157485e-01\n",
            "     5.11280894e-01  1.78496695e+00]\n",
            "   [ 1.11333883e+00  1.62665915e+00  5.01242340e-01 ...  4.01923776e-01\n",
            "     1.59225976e+00  2.26838604e-01]\n",
            "   ...\n",
            "   [-8.71223986e-01 -3.64277661e-01  9.07023489e-01 ... -5.46318710e-01\n",
            "     6.32839322e-01  3.33051346e-02]\n",
            "   [-5.30150354e-01  1.68116164e+00 -5.35234213e-01 ... -1.14391193e-01\n",
            "     1.37856972e+00 -5.47652185e-01]\n",
            "   [ 1.83075219e-01 -1.43695325e-01  5.11611044e-01 ... -4.79151338e-01\n",
            "     5.93400955e-01  4.55174297e-01]]]\n",
            "\n",
            "\n",
            " [[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 2.35165969e-01  8.47342551e-01  9.63916838e-01 ...  4.95054185e-01\n",
            "     5.10453224e-01  1.73817813e+00]\n",
            "   [ 2.09054217e-01  1.75989494e-01  0.00000000e+00 ...  9.20907333e-02\n",
            "     9.52964798e-02  6.64764643e-01]\n",
            "   [ 2.42320612e-01  2.55807847e-01  2.15249613e-01 ...  7.20237568e-02\n",
            "     1.26772478e-01  6.77378893e-01]\n",
            "   ...\n",
            "   [ 5.65790832e-01  9.36357439e-01  7.94692218e-01 ...  9.17829573e-01\n",
            "     8.76496613e-01  9.66745079e-01]\n",
            "   [ 2.64532864e-01  2.22507730e-01  4.20408070e-01 ...  1.12675393e+00\n",
            "     1.09872687e+00  7.53369272e-01]\n",
            "   [ 1.41392842e-01  1.51409268e-01  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  7.02660739e-01]]\n",
            "\n",
            "  [[ 6.30324543e-01  5.00331819e-01  0.00000000e+00 ...  3.55516046e-01\n",
            "     4.55596507e-01  3.45966548e-01]\n",
            "   [ 5.72890520e-01  8.25666189e-01  7.24544704e-01 ...  2.52235681e-01\n",
            "     3.12946260e-01  3.05549741e-01]\n",
            "   [ 5.77009141e-01  4.97845918e-01  8.27552021e-01 ...  2.30880708e-01\n",
            "     3.42461735e-01  3.81694227e-01]\n",
            "   ...\n",
            "   [ 1.55413175e+00  1.36202443e+00  5.79529226e-01 ...  8.48779261e-01\n",
            "     9.25011337e-01  8.61592650e-01]\n",
            "   [ 4.99977797e-01  5.70998907e-01  1.07935739e+00 ...  1.14618623e+00\n",
            "     1.01422977e+00  8.08148146e-01]\n",
            "   [ 2.26155281e-01  5.35572231e-01  7.32768834e-01 ...  3.87645274e-01\n",
            "     0.00000000e+00  4.54692841e-02]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 3.25249583e-01  2.39279199e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 2.70974785e-01  1.24870086e+00  2.65831423e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 2.54848570e-01  3.76425013e-02  4.98864681e-01 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 1.55398861e-01  4.30937633e-02  0.00000000e+00 ...  0.00000000e+00\n",
            "     4.13294956e-02  0.00000000e+00]\n",
            "   [ 2.64244080e-01  1.41445965e-01  1.41127314e-02 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 7.34722137e-01  2.92393535e-01  3.84536892e-01 ...  0.00000000e+00\n",
            "     0.00000000e+00  5.54514006e-02]]\n",
            "\n",
            "  [[ 1.92926109e+00  2.23772168e+00  2.76673865e+00 ...  2.35258651e+00\n",
            "     2.33055830e+00  2.38570237e+00]\n",
            "   [ 1.61331141e+00  1.46422613e+00  1.43516970e+00 ...  1.88873577e+00\n",
            "     1.88165152e+00  1.79881275e+00]\n",
            "   [ 1.59859538e+00  1.48571301e+00  1.44053757e+00 ...  1.92231846e+00\n",
            "     1.88573766e+00  1.83378553e+00]\n",
            "   ...\n",
            "   [ 1.93256485e+00  1.40357482e+00  1.64655638e+00 ...  2.24895835e+00\n",
            "     2.14535475e+00  1.94967687e+00]\n",
            "   [ 1.67305350e+00  1.80702364e+00  1.82984614e+00 ...  2.21391416e+00\n",
            "     2.18961167e+00  1.82867539e+00]\n",
            "   [ 1.78017509e+00  1.34298515e+00  1.41624081e+00 ...  1.29253662e+00\n",
            "     1.41482675e+00  1.01633489e+00]]\n",
            "\n",
            "  [[ 2.30981803e+00  4.31396675e+00  5.97496128e+00 ...  4.80878735e+00\n",
            "     4.61722851e+00  4.50586033e+00]\n",
            "   [ 2.18050265e+00  2.72235250e+00  5.66246986e+00 ...  4.84969902e+00\n",
            "     4.64207411e+00  4.37572145e+00]\n",
            "   [ 2.21296358e+00  2.36141300e+00  2.35701346e+00 ...  4.73649120e+00\n",
            "     4.54410887e+00  4.26109934e+00]\n",
            "   ...\n",
            "   [ 2.39059615e+00  2.57816792e+00  2.50459290e+00 ...  4.51389408e+00\n",
            "     4.15017462e+00  4.01902580e+00]\n",
            "   [ 2.49268746e+00  2.51208258e+00  2.39211607e+00 ...  4.17218018e+00\n",
            "     4.34598541e+00  3.75253844e+00]\n",
            "   [ 2.40162516e+00  2.44077492e+00  2.53608155e+00 ...  3.96276402e+00\n",
            "     4.47793627e+00  4.18999863e+00]]]\n",
            "\n",
            "\n",
            " [[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 5.08574128e-01  5.20686924e-01  5.40306151e-01 ...  5.51444530e-01\n",
            "     5.34857333e-01  1.40920246e+00]\n",
            "   [ 3.81296486e-01  3.23746920e-01  3.55007768e-01 ...  2.29575232e-01\n",
            "     2.35787183e-01  8.30616891e-01]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  2.15037033e-01\n",
            "     2.40942195e-01  8.27605844e-01]\n",
            "   ...\n",
            "   [ 2.18315259e-01  1.79192400e+00  1.10975015e+00 ...  4.07757664e+00\n",
            "     3.62180018e+00  2.36938691e+00]\n",
            "   [ 0.00000000e+00  7.67577887e-01  5.16906917e-01 ...  6.19166315e-01\n",
            "     6.80212319e-01  1.11371529e+00]\n",
            "   [ 1.28132552e-01  0.00000000e+00  0.00000000e+00 ...  2.04223439e-01\n",
            "     6.24485075e-01  1.51502788e+00]]\n",
            "\n",
            "  [[ 4.42943722e-01  5.40511787e-01  4.71111029e-01 ...  4.78937328e-01\n",
            "     4.91683602e-01  5.93644083e-01]\n",
            "   [ 5.21767795e-01  6.77806914e-01  5.97478330e-01 ...  4.07368153e-01\n",
            "     4.56453353e-01  4.76497889e-01]\n",
            "   [ 6.01817369e-01  4.78438884e-01  1.13710988e+00 ...  4.70372230e-01\n",
            "     4.77132708e-01  4.97024328e-01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  4.02691269e+00  0.00000000e+00 ...  1.83034587e+00\n",
            "     2.59804678e+00  2.16405129e+00]\n",
            "   [ 0.00000000e+00  3.89732814e+00  0.00000000e+00 ...  1.10441554e+00\n",
            "     7.85709858e-01  6.93492055e-01]\n",
            "   [ 1.05258867e-01  1.81347835e+00  0.00000000e+00 ...  5.84459662e-01\n",
            "     7.93922842e-01  9.77643669e-01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  2.06197882e+00  1.82485604e+00 ...  8.88654709e-01\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  1.11859107e+00  1.17367625e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 6.39189720e-01  9.78655815e-01  9.79809642e-01 ...  5.30247509e-01\n",
            "     9.35739040e-01  1.02115011e+00]]\n",
            "\n",
            "  [[ 2.27920485e+00  2.03182101e+00  2.03199077e+00 ...  2.05743456e+00\n",
            "     2.08243060e+00  2.07099199e+00]\n",
            "   [ 1.88969111e+00  1.78152084e+00  1.83625257e+00 ...  1.77985740e+00\n",
            "     1.79449952e+00  1.75307143e+00]\n",
            "   [ 2.80630970e+00  2.22959089e+00  2.03023076e+00 ...  1.80225360e+00\n",
            "     1.78110659e+00  1.75726664e+00]\n",
            "   ...\n",
            "   [ 2.50347733e+00  8.93497646e-01  1.10815978e+00 ...  1.34496939e+00\n",
            "     1.39617360e+00  1.52745152e+00]\n",
            "   [ 2.87302804e+00  1.27899516e+00  1.15811646e+00 ...  1.81238902e+00\n",
            "     1.81011534e+00  1.97869587e+00]\n",
            "   [ 8.05831552e-01  1.02729857e+00  1.11963522e+00 ...  1.58895218e+00\n",
            "     1.36797845e+00  9.77004051e-01]]\n",
            "\n",
            "  [[ 3.30181503e+00  3.33408165e+00  3.37170434e+00 ...  3.54397011e+00\n",
            "     3.47460604e+00  3.39216614e+00]\n",
            "   [ 3.29337001e+00  3.35161781e+00  3.36784506e+00 ...  3.56275892e+00\n",
            "     3.48446465e+00  3.35565400e+00]\n",
            "   [ 4.52031755e+00  4.46153593e+00  3.52218103e+00 ...  3.50234842e+00\n",
            "     3.45749354e+00  3.34040594e+00]\n",
            "   ...\n",
            "   [ 4.09592342e+00  5.59038925e+00  6.64701557e+00 ...  3.54301071e+00\n",
            "     1.98238814e+00  1.67975962e+00]\n",
            "   [ 4.22269249e+00  3.24175644e+00  4.79137135e+00 ...  2.07491326e+00\n",
            "     2.11306548e+00  2.06229949e+00]\n",
            "   [ 4.56091022e+00  4.06559753e+00  4.55567026e+00 ...  2.07392836e+00\n",
            "     2.03652072e+00  1.92161834e+00]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 5.22140443e-01  1.52590573e+00  1.99699056e+00 ...  8.66667151e-01\n",
            "     6.56373739e-01  2.14356160e+00]\n",
            "   [ 2.69079089e-01  7.47425202e-03  1.69297588e+00 ...  1.54206529e-01\n",
            "     6.12014011e-02  2.96964467e-01]\n",
            "   [ 3.05482715e-01  3.89420167e-02  5.48700765e-02 ...  6.02644458e-02\n",
            "     2.72784412e-01  1.02839708e+00]\n",
            "   ...\n",
            "   [ 6.88598096e-01  4.60413873e-01  3.01029563e-01 ...  4.09434319e-01\n",
            "     4.30023164e-01  9.13948774e-01]\n",
            "   [ 5.10030508e-01  1.64669111e-01  5.53841218e-02 ...  5.89892343e-02\n",
            "     2.13555169e+00  1.87234533e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  5.03059566e-01]]\n",
            "\n",
            "  [[ 0.00000000e+00  1.09237909e+00  1.91849744e+00 ...  1.92744505e+00\n",
            "     2.56965905e-01  4.52615738e-01]\n",
            "   [ 1.65981114e-01  1.90051794e-01  7.70891830e-02 ...  1.46084142e+00\n",
            "     6.80314183e-01  4.00512844e-01]\n",
            "   [ 3.10262173e-01  3.67208242e-01  3.45888138e-01 ...  1.55114305e+00\n",
            "     4.00337994e-01  0.00000000e+00]\n",
            "   ...\n",
            "   [ 2.45687276e-01  4.65005934e-01  4.17937726e-01 ...  5.48000157e-01\n",
            "     7.46025920e-01  6.30178571e-01]\n",
            "   [ 0.00000000e+00  3.83871645e-01  3.11709255e-01 ...  5.65225124e-01\n",
            "     1.07464468e+00  1.16599214e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  1.20284550e-01\n",
            "     7.71048248e-01  6.98128164e-01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 4.84133333e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 2.69661951e+00  2.51121378e+00  2.08337522e+00 ...  2.67826438e+00\n",
            "     2.60203886e+00  2.69599032e+00]\n",
            "   [ 1.84096897e+00  1.81765866e+00  1.73788989e+00 ...  2.12802434e+00\n",
            "     2.08721042e+00  2.66990733e+00]\n",
            "   [ 2.05509448e+00  1.89577305e+00  1.88095975e+00 ...  2.18880677e+00\n",
            "     2.88483930e+00  2.37699628e+00]\n",
            "   ...\n",
            "   [ 2.13572288e+00  2.20636725e+00  2.03460407e+00 ...  1.86088467e+00\n",
            "     2.65376163e+00  2.09004331e+00]\n",
            "   [ 2.07079649e+00  2.10614800e+00  2.17501616e+00 ...  2.42584705e+00\n",
            "     1.63142192e+00  1.23135638e+00]\n",
            "   [ 1.96191370e+00  1.29477942e+00  1.31553555e+00 ...  8.59708786e-01\n",
            "     1.21128070e+00  9.07997072e-01]]\n",
            "\n",
            "  [[ 4.57676792e+00  4.68985271e+00  3.68955684e+00 ...  5.86870050e+00\n",
            "     5.90759277e+00  5.78154945e+00]\n",
            "   [ 4.34114981e+00  4.50465679e+00  4.57463646e+00 ...  6.05021572e+00\n",
            "     5.80157948e+00  5.57136059e+00]\n",
            "   [ 4.06860971e+00  4.21521187e+00  4.35829830e+00 ...  6.71544075e+00\n",
            "     7.73094845e+00  7.67783356e+00]\n",
            "   ...\n",
            "   [ 5.12143278e+00  5.25524902e+00  5.18989658e+00 ...  3.29596734e+00\n",
            "     3.04264736e+00  2.77893305e+00]\n",
            "   [ 5.16774130e+00  5.35539150e+00  5.44116497e+00 ...  3.07044983e+00\n",
            "     2.70059919e+00  2.69643760e+00]\n",
            "   [ 5.26795530e+00  5.30320930e+00  5.12443256e+00 ...  3.04153490e+00\n",
            "     2.62285519e+00  2.83081293e+00]]]\n",
            "\n",
            "\n",
            " [[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 4.54850912e-01  4.25453007e-01  4.30016637e-01 ...  2.70357311e-01\n",
            "     2.24904251e+00  1.19980824e+00]\n",
            "   [ 3.28853250e-01  2.95077145e-01  2.57300138e-01 ...  0.00000000e+00\n",
            "     0.00000000e+00  6.39820039e-01]\n",
            "   [ 3.12404037e-01  2.28961393e-01  2.24060252e-01 ...  0.00000000e+00\n",
            "     2.14464962e-01  1.65221989e+00]\n",
            "   ...\n",
            "   [ 5.18513799e-01  3.46462488e-01  2.77396798e-01 ...  0.00000000e+00\n",
            "     1.94221213e-02  2.07234159e-01]\n",
            "   [ 6.71098530e-01  3.16690534e-01  2.27252707e-01 ...  0.00000000e+00\n",
            "     0.00000000e+00  4.51600283e-01]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 3.86061192e-01  4.38375741e-01  4.59097505e-01 ...  1.13865745e+00\n",
            "     4.87124681e-01  1.38132894e+00]\n",
            "   [ 3.87618452e-01  4.07284409e-01  4.27126110e-01 ...  1.14612091e+00\n",
            "     0.00000000e+00  6.53094471e-01]\n",
            "   [ 4.11620170e-01  4.58300620e-01  3.06783319e-01 ...  1.04517233e+00\n",
            "     0.00000000e+00  9.89639044e-01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  3.54965776e-01  5.74481368e-01 ...  3.88279706e-01\n",
            "     4.51430768e-01  0.00000000e+00]\n",
            "   [ 3.36436599e-01  5.08645952e-01  5.52269399e-01 ...  0.00000000e+00\n",
            "     1.76735610e-01  0.00000000e+00]\n",
            "   [ 8.96886662e-02  1.33822739e-01  1.46133989e-01 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 1.93418220e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 1.60552949e-01  0.00000000e+00  0.00000000e+00 ...  2.58219332e-01\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 1.70386359e-01  0.00000000e+00  0.00000000e+00 ...  4.65921670e-01\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 7.29500592e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 2.82941401e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 5.45233548e-01  0.00000000e+00  0.00000000e+00 ...  1.38461900e+00\n",
            "     5.07779658e-01  0.00000000e+00]]\n",
            "\n",
            "  [[ 2.31313682e+00  2.16820216e+00  2.15364575e+00 ...  3.03093147e+00\n",
            "     3.04034543e+00  1.83843553e+00]\n",
            "   [ 1.82757306e+00  1.79696357e+00  1.81548464e+00 ...  2.17429137e+00\n",
            "     2.56859422e+00  1.53590488e+00]\n",
            "   [ 1.85183871e+00  1.82283795e+00  1.87123454e+00 ...  2.23677635e+00\n",
            "     2.37498951e+00  1.43303812e+00]\n",
            "   ...\n",
            "   [ 1.77734733e+00  1.66470253e+00  1.67818093e+00 ...  2.30869627e+00\n",
            "     2.08041930e+00  2.06487250e+00]\n",
            "   [ 1.95247853e+00  1.74943960e+00  1.75842762e+00 ...  1.59652197e+00\n",
            "     2.16962099e+00  2.17155671e+00]\n",
            "   [ 1.46918881e+00  1.36829150e+00  1.40926981e+00 ...  0.00000000e+00\n",
            "     1.04466379e+00  5.65673828e-01]]\n",
            "\n",
            "  [[ 3.26780200e+00  3.40015244e+00  3.45031714e+00 ...  6.60157442e+00\n",
            "     6.55482483e+00  6.46026134e+00]\n",
            "   [ 3.23490691e+00  3.45006919e+00  3.50208616e+00 ...  6.89565897e+00\n",
            "     7.03907776e+00  6.81187677e+00]\n",
            "   [ 3.23896837e+00  3.49761367e+00  3.70640993e+00 ...  6.94560719e+00\n",
            "     6.97232628e+00  6.94147015e+00]\n",
            "   ...\n",
            "   [ 3.60482335e+00  3.72310758e+00  3.81542706e+00 ...  6.84736443e+00\n",
            "     6.66634989e+00  6.72205925e+00]\n",
            "   [ 3.45688391e+00  3.55725741e+00  3.50950527e+00 ...  6.71940136e+00\n",
            "     6.64673805e+00  6.52851534e+00]\n",
            "   [ 3.44031096e+00  3.42852163e+00  3.52729464e+00 ...  5.75630474e+00\n",
            "     6.03946400e+00  6.20682430e+00]]]\n",
            "\n",
            "\n",
            " [[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 3.91299099e-01  4.39448416e-01  5.04211843e-01 ...  0.00000000e+00\n",
            "     2.85108209e+00  7.70434558e-01]\n",
            "   [ 3.34623128e-01  3.25268537e-01  3.74422789e-01 ...  1.72922707e+00\n",
            "     1.38612139e+00  1.86386478e+00]\n",
            "   [ 3.29558313e-01  2.78841078e-01  3.02254617e-01 ...  7.46711314e-01\n",
            "     5.52509665e-01  9.86092448e-01]\n",
            "   ...\n",
            "   [ 1.08514273e+00  7.73792088e-01  1.37289035e+00 ...  1.30199456e+00\n",
            "     1.84779719e-01  5.89694560e-01]\n",
            "   [ 8.88758674e-02  2.38059536e-01  1.67184100e-01 ...  1.21814954e+00\n",
            "     1.93130329e-01  6.02434397e-01]\n",
            "   [ 0.00000000e+00  0.00000000e+00  1.62542403e-01 ...  1.49715841e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 4.49064046e-01  6.00297928e-01  7.12622344e-01 ...  1.47812039e-01\n",
            "     9.11455095e-01  2.29836011e+00]\n",
            "   [ 3.89457375e-01  5.26901364e-01  6.08934343e-01 ...  2.62094522e+00\n",
            "     3.00585151e+00  1.43518960e+00]\n",
            "   [ 3.06739837e-01  4.32938516e-01  4.62809026e-01 ...  2.20721674e+00\n",
            "     5.34645855e-01  1.53904402e+00]\n",
            "   ...\n",
            "   [ 4.57835406e-01  5.68996370e-01  5.79794407e-01 ...  1.29465640e-01\n",
            "     4.66994673e-01  1.87981337e-01]\n",
            "   [ 4.82393026e-01  4.92117971e-01  5.54434478e-01 ...  2.20260549e+00\n",
            "     4.99041229e-01  1.74320728e-01]\n",
            "   [ 5.73603868e-01  5.27003109e-01  4.07508075e-01 ...  1.25728226e+00\n",
            "     8.13522041e-02  0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 5.22382483e-02  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 1.05700217e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 9.42386985e-02  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     1.42729655e-01  0.00000000e+00]\n",
            "   ...\n",
            "   [ 2.72494942e-01  0.00000000e+00  0.00000000e+00 ...  6.59131110e-02\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 5.02353668e-01  9.86096263e-01  1.10944200e+00 ...  1.23067223e-01\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 9.97851133e-01  1.56448197e+00  1.60530949e+00 ...  5.54029822e-01\n",
            "     7.15206936e-02  0.00000000e+00]]\n",
            "\n",
            "  [[ 2.43237805e+00  2.15014863e+00  2.11416459e+00 ...  3.59061432e+00\n",
            "     3.14936614e+00  8.93120408e-01]\n",
            "   [ 1.96224737e+00  1.85887134e+00  1.83100247e+00 ...  9.84431922e-01\n",
            "     1.83350050e+00  1.66923642e+00]\n",
            "   [ 1.98610926e+00  1.87038743e+00  1.85367954e+00 ...  1.82768893e+00\n",
            "     1.95923865e+00  1.82835340e+00]\n",
            "   ...\n",
            "   [ 1.94944990e+00  1.93407309e+00  1.93780565e+00 ...  1.27559483e+00\n",
            "     1.82239640e+00  1.83364224e+00]\n",
            "   [ 2.32811189e+00  1.85889947e+00  1.74272621e+00 ...  1.65378404e+00\n",
            "     1.78658652e+00  1.80675972e+00]\n",
            "   [ 1.65362632e+00  1.37860405e+00  1.35152829e+00 ...  1.41985786e+00\n",
            "     1.41511416e+00  1.38592577e+00]]\n",
            "\n",
            "  [[ 3.25729418e+00  3.25614834e+00  3.13834238e+00 ...  4.14391422e+00\n",
            "     3.73599577e+00  1.63637769e+00]\n",
            "   [ 3.45898199e+00  3.50569463e+00  3.36576509e+00 ...  3.92728567e+00\n",
            "     2.40819716e+00  2.04875231e+00]\n",
            "   [ 3.62108088e+00  3.69558644e+00  3.60642529e+00 ...  3.06342077e+00\n",
            "     3.14355278e+00  2.03257895e+00]\n",
            "   ...\n",
            "   [ 3.45899606e+00  3.49088645e+00  3.45718861e+00 ...  3.93221140e+00\n",
            "     3.77636051e+00  3.75743318e+00]\n",
            "   [ 3.28571701e+00  3.40291643e+00  3.40904570e+00 ...  3.35122585e+00\n",
            "     3.72273874e+00  3.72613764e+00]\n",
            "   [ 3.09353232e+00  3.08666897e+00  2.93664074e+00 ...  3.50686669e+00\n",
            "     3.65884399e+00  3.65666819e+00]]]]\n",
            "num_images: 7501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahEfLpznITlQ",
        "outputId": "15ed1bb9-1594-4934-e985-32ff95f46837"
      },
      "source": [
        "print('embedding shape:', embedding.shape)\n",
        "last_img_embedding = embedding[7500:, :, :, ]\n",
        "print('\\n embedding shape of the last image for instance:', last_img_embedding.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedding shape: torch.Size([7501, 256, 16, 16])\n",
            "\n",
            " embedding shape of the last image for instance: torch.Size([1, 256, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1z3KUOyHkCu"
      },
      "source": [
        "def compute_similar_images(image, num_images, embedding, device):\n",
        "    \"\"\"\n",
        "    Given an image and number of similar images to search.\n",
        "    Returns the num_images closest neares images.\n",
        "    Args:\n",
        "    image: Image whose similar images are to be found.\n",
        "    num_images: Number of similar images to find.\n",
        "    embedding : A (num_images, embedding_dim) Embedding of images learnt from auto-encoder.\n",
        "    device : \"cuda\" or \"cpu\" device.\n",
        "    \"\"\"\n",
        "    \n",
        "    image_tensor = T.ToTensor()(image)\n",
        "    image_tensor = image_tensor.unsqueeze(0)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        image_embedding = encoder(image_tensor).cpu().detach().numpy()\n",
        "        \n",
        "    flattened_embedding = image_embedding.reshape((image_embedding.shape[0], -1))\n",
        "\n",
        "    knn = NearestNeighbors(n_neighbors=num_images, metric=\"cosine\")\n",
        "    knn.fit(embedding)\n",
        "\n",
        "    _, indices = knn.kneighbors(flattened_embedding)\n",
        "    indices_list = indices.tolist()\n",
        "    return indices_list"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}