{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageSimilarity.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACBOPThLAqQW"
      },
      "source": [
        "import torch, os\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUny_OP3NTpr"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    device = \"cpu\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8B4Z7XnB0lr",
        "outputId": "d3fd53d3-f255-4df9-8b33-73de4ad8797b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "I1kGaQ4CkIzR",
        "outputId": "9b4b3393-9ba7-4b99-a2de-c1e3163e0ea0"
      },
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/imagenames.csv\")\n",
        "test_df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>IMG4287_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>IMG4288_5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IMG4289_5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IMG4290_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>IMG4291_5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>IMG5482_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>IMG5483_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>IMG5484_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>IMG5485_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>IMG5486_2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             id\n",
              "0     IMG4287_3\n",
              "1     IMG4288_5\n",
              "2     IMG4289_5\n",
              "3     IMG4290_4\n",
              "4     IMG4291_5\n",
              "...         ...\n",
              "1195  IMG5482_1\n",
              "1196  IMG5483_2\n",
              "1197  IMG5484_4\n",
              "1198  IMG5485_3\n",
              "1199  IMG5486_2\n",
              "\n",
              "[1200 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHLp1kT1Atbd"
      },
      "source": [
        "# SOURCE: https://medium.com/pytorch/image-similarity-search-in-pytorch-1a744cf3469\n",
        "# Dataset class converting all images in the train/test folder to PyTorch dataset\n",
        "class FolderDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Creates a PyTorch dataset from a given folder containing images and returns two tensor images. \n",
        "    :param main_dir: directory where images are stored.\n",
        "    #:param transform: torchvision transforms to be applied while making dataset (optional) \n",
        "    :return: two images, one as input to the model and another image to compare with the original image for reconstruction.\n",
        "    \"\"\"\n",
        "    def __init__(self, main_dir, transform=None):\n",
        "        self.main_dir = main_dir\n",
        "        self.transform = transform\n",
        "        self.all_imgs = os.listdir(main_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_loc = os.path.join(self.main_dir, self.all_imgs[idx])\n",
        "        image = Image.open(img_loc).convert(\"RGB\")   # our image size is (680, 490), I had to scale them to 512*512 to handle a bug related to tensor size\n",
        "        scale = T.Compose([T.Scale((512,512))])\n",
        "        image = scale(image)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            tensor_image = self.transform(image)\n",
        "\n",
        "        return tensor_image, tensor_image\n",
        "        "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mne87Pr9A7E7"
      },
      "source": [
        "class ConvEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolutional Encoder Model which is a a repetition of convolutional, relu and maxpool layers.\n",
        "    It converts an input images to a feature representation of size (1, 256, 16, 16).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, (3, 3), padding=(1, 1))\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.maxpool1 = nn.MaxPool2d((2, 2))\n",
        "        self.conv2 = nn.Conv2d(16, 32, (3, 3), padding=(1, 1))\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.maxpool2 = nn.MaxPool2d((2, 2))\n",
        "        self.conv3 = nn.Conv2d(32, 64, (3, 3), padding=(1, 1))\n",
        "        self.relu3 = nn.ReLU(inplace=True)\n",
        "        self.maxpool3 = nn.MaxPool2d((2, 2))\n",
        "        self.conv4 = nn.Conv2d(64, 128, (3, 3), padding=(1, 1))\n",
        "        self.relu4 = nn.ReLU(inplace=True)\n",
        "        self.maxpool4 = nn.MaxPool2d((2, 2))\n",
        "        self.conv5 = nn.Conv2d(128, 256, (3, 3), padding=(1, 1))\n",
        "        self.relu5 = nn.ReLU(inplace=True)\n",
        "        self.maxpool5 = nn.MaxPool2d((2, 2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Downscale the image with conv maxpool\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.maxpool2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.maxpool3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.relu4(x)\n",
        "        x = self.maxpool4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.relu5(x)\n",
        "        x = self.maxpool5(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC5TQICnBB6T"
      },
      "source": [
        "class ConvDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolutional Decoder Model takes an input of feature representations and reconstructs back the image\n",
        "    It upscales the feature representations to the original image using transposed convolution layers of kernel size (2, 2) and stride (2, 2)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.deconv1 = nn.ConvTranspose2d(256, 128, (2, 2), stride=(2, 2))\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.deconv2 = nn.ConvTranspose2d(128, 64, (2, 2), stride=(2, 2))\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.deconv3 = nn.ConvTranspose2d(64, 32, (2, 2), stride=(2, 2))\n",
        "        self.relu3 = nn.ReLU(inplace=True)\n",
        "        self.deconv4 = nn.ConvTranspose2d(32, 16, (2, 2), stride=(2, 2))\n",
        "        self.relu4 = nn.ReLU(inplace=True)\n",
        "        self.deconv5 = nn.ConvTranspose2d(16, 3, (2, 2), stride=(2, 2))\n",
        "        self.relu5 = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Upscale the image with convtranspose etc.\n",
        "        x = self.deconv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.deconv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.deconv3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.deconv4(x)\n",
        "        x = self.relu4(x)\n",
        "        x = self.deconv5(x)\n",
        "        x = self.relu5(x)\n",
        "        return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PPVW9isMakl"
      },
      "source": [
        "def train_step(encoder, decoder, train_loader, loss_fn, optimizer, device):\n",
        "    \"\"\"\n",
        "    Performs a single training step\n",
        "    :param encoder: the convolutional Encoder defined as ConvEncoder\n",
        "    :param decoder: A convolutional Decoder defined as ConvDecoder\n",
        "    :param train_loader: PyTorch dataloader, containing (images, images).\n",
        "    :param loss_fn: PyTorch loss_fn to compute loss between 2 images.\n",
        "    :param optimizer: PyTorch optimizer (eg. AdamW)\n",
        "    :param device: \"cuda\" or \"cpu\"\n",
        "    :returns: Train Loss\n",
        "    \"\"\"\n",
        "    #  Set networks to train mode.\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "\n",
        "    for batch_idx, (train_img, target_img) in enumerate(train_loader):\n",
        "        train_img = train_img.to(device)\n",
        "        target_img = target_img.to(device)\n",
        "        \n",
        "        # Zero grad the optimizer\n",
        "        optimizer.zero_grad()\n",
        "        # Feed the train images to encoder\n",
        "        enc_output = encoder(train_img)\n",
        "        dec_output = decoder(enc_output)\n",
        "        # Compute loss between the reconstructed image and orginal image which is target image.\n",
        "        loss = loss_fn(dec_output, target_img)\n",
        "        loss.backward()\n",
        "        # Apply the optimizer to network\n",
        "        optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def val_step(encoder, decoder, val_loader, loss_fn, device):\n",
        "    \"\"\"\n",
        "    Performs a single training step\n",
        "    :param encoder: A convolutional Encoder like torch_model ConvEncoder\n",
        "    :param decoder: A convolutional Decoder like torch_model ConvDecoder\n",
        "    :param val_loader: PyTorch dataloader containing (images, images)\n",
        "    :param loss_fn: PyTorch loss_fnto compute loss between 2 images\n",
        "    :param device: \"cuda\" or \"cpu\"\n",
        "    :returns: Validation Loss\n",
        "    \"\"\"\n",
        "    # Set to eval mode.\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    \n",
        "    # gradients do not need to be computed  for validation???\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (train_img, target_img) in enumerate(val_loader):\n",
        "            train_img = train_img.to(device)\n",
        "            target_img = target_img.to(device)\n",
        "            # Feed the train images to encoder\n",
        "            enc_output = encoder(train_img)\n",
        "            # Feed the encoder output to Decoder to reconstruct the image\n",
        "            dec_output = decoder(enc_output)\n",
        "            # Find the validation loss for the encoder and decoder \n",
        "            loss = loss_fn(dec_output, target_img)\n",
        "    return loss.item()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wkz1ZgfUvUvX"
      },
      "source": [
        "def create_embedding(encoder, full_loader, embedding_dim, device):\n",
        "    \"\"\"\n",
        "    Creates embedding using encoder from dataloader and saves our image embeddings.\n",
        "    :param encoder: A convolutional Encoder like torch_model ConvEncoder\n",
        "    :param full_loader: PyTorch dataloader, containing (images, images) over the entire dataset\n",
        "    :param embedding_dim: Tuple (c, h, w) Dimension of embedding = output of encoder dimesntions.\n",
        "    :param device: \"cuda\" or \"cpu\"\n",
        "    : return: Embedding of size (num_images_in_loader + 1, c, h, w)\n",
        "    \"\"\"\n",
        "    # Set encoder to eval mode.\n",
        "    encoder.eval()\n",
        "    # Just a place holder for our 0th image embedding.\n",
        "    embedding = torch.randn(embedding_dim)\n",
        "    \n",
        "    # no_grad as we do not compute loss here\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (train_img, target_img) in enumerate(full_loader):\n",
        "            train_img = train_img.to(device)\n",
        "            # Get encoder outputs and move outputs to cpu\n",
        "            enc_output = encoder(train_img).cpu()\n",
        "            # Add the outputs to embeddings\n",
        "            embedding = torch.cat((embedding, enc_output), 0)\n",
        "    return embedding"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk3qPMRYBIWL",
        "outputId": "af0c10fe-df40-406e-d129-358b1989fa86"
      },
      "source": [
        "# Create the PyTorch `dataset` and the `dataloaders`\n",
        "transforms = T.Compose([T.ToTensor()]) # Normalize the pixels and convert to tensor\n",
        "# Create folder dataset\n",
        "full_dataset = FolderDataset(\"/content/drive/MyDrive/train\", transforms) \n",
        "\n",
        "train_size = int(0.75 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "\n",
        "# Split data to train and test\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# Create the train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "# Create the validation dataloader\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "# Create the full dataloader\n",
        "full_loader = torch.utils.data.DataLoader(full_dataset, batch_size=32)\n",
        "\n",
        "# Mean squared lossto compute difference between two images\n",
        "encoder = ConvEncoder() \n",
        "decoder = ConvDecoder()\n",
        "device = \"cuda\" \n",
        "max_loss = 9999\n",
        "\n",
        "# Shift models to GPU\n",
        "encoder.to(device)\n",
        "decoder.to(device)\n",
        "\n",
        "# The enocder and decoder parameters\n",
        "print(encoder.parameters())\n",
        "autoencoder_params = list(encoder.parameters()) + list(decoder.parameters())\n",
        "# Adam Optimizer\n",
        "optimizer = optim.AdamW(autoencoder_params, lr=1e-3)\n",
        "\n",
        "total_epochs = 10\n",
        "# Got these values from the encoder\n",
        "embedding_shape = (1, 256, 16, 16)\n",
        "\n",
        "for epoch in tqdm(range(total_epochs)):\n",
        "        train_loss = train_step(encoder, decoder, train_loader, nn.MSELoss(), optimizer, device=device)   \n",
        "        print(f\"Epochs = {epoch}, Training Loss : {train_loss}\")\n",
        "        val_loss = val_step(encoder, decoder, val_loader, nn.MSELoss(), device=device)   \n",
        "        print(f\"Epochs = {epoch}, Validation Loss : {val_loss}\")\n",
        "        # Simple Best Model saving\n",
        "        if val_loss < max_loss:\n",
        "            print(\"Validation Loss decreased, saving new best model\")\n",
        "            torch.save(encoder.state_dict(), \"encoder_model.pt\")\n",
        "            torch.save(decoder.state_dict(), \"decoder_model.pt\")\n",
        "\n",
        "# We need feature representations for the complete dataset as well (i.e full_loader)\n",
        "embedding = create_embedding(encoder, full_loader, embedding_shape, device)\n",
        "# Convert embedding to numpy and save them\n",
        "numpy_embedding = embedding.cpu().detach().numpy()\n",
        "print('numpy_embedding:', numpy_embedding)\n",
        "num_images = numpy_embedding.shape[0]\n",
        "\n",
        "# Save the embeddings for complete dataset\n",
        "flattened_embedding = numpy_embedding.reshape((num_images, -1))\n",
        "np.save(\"data_embedding.npy\", flattened_embedding)            \n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object Module.parameters at 0x7f59042378d0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:310: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs = 0, Training Loss : 0.011093203909695148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [24:16<3:38:26, 1456.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs = 0, Validation Loss : 0.010468840599060059\n",
            "Validation Loss decreased, saving new best model\n",
            "Epochs = 1, Training Loss : 0.005519292317330837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [26:20<1:29:40, 672.53s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs = 1, Validation Loss : 0.005793792195618153\n",
            "Validation Loss decreased, saving new best model\n",
            "Epochs = 2, Training Loss : 0.005569281987845898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [28:23<49:11, 421.57s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs = 2, Validation Loss : 0.0041328356601297855\n",
            "Validation Loss decreased, saving new best model\n",
            "Epochs = 3, Training Loss : 0.00417742133140564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [30:25<30:20, 303.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs = 3, Validation Loss : 0.003605941543355584\n",
            "Validation Loss decreased, saving new best model\n",
            "Epochs = 4, Training Loss : 0.0045937891118228436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [32:28<19:51, 238.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs = 4, Validation Loss : 0.003322718432173133\n",
            "Validation Loss decreased, saving new best model\n",
            "Epochs = 5, Training Loss : 0.0032663573510944843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [34:31<13:16, 199.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs = 5, Validation Loss : 0.0031313274521380663\n",
            "Validation Loss decreased, saving new best model\n",
            "Epochs = 6, Training Loss : 0.003957951907068491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [36:33<08:42, 174.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs = 6, Validation Loss : 0.003285658545792103\n",
            "Validation Loss decreased, saving new best model\n",
            "Epochs = 7, Training Loss : 0.003755912883207202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [38:38<05:16, 158.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs = 7, Validation Loss : 0.0028864911291748285\n",
            "Validation Loss decreased, saving new best model\n",
            "Epochs = 8, Training Loss : 0.005124012939631939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [40:41<02:27, 147.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs = 8, Validation Loss : 0.002975414041429758\n",
            "Validation Loss decreased, saving new best model\n",
            "Epochs = 9, Training Loss : 0.004047607071697712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [42:44<00:00, 256.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs = 9, Validation Loss : 0.0032191702630370855\n",
            "Validation Loss decreased, saving new best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy_embedding: [[[[-2.15307802e-01  1.27419400e+00  1.11482489e+00 ... -4.03616101e-01\n",
            "    -1.31118751e+00  2.06213951e-01]\n",
            "   [ 1.31526768e+00  8.20715845e-01  5.52603006e-01 ...  2.58888632e-01\n",
            "     5.48661888e-01 -1.01492679e+00]\n",
            "   [ 5.29578090e-01  8.09661150e-01  1.71489269e-02 ...  2.62416512e-01\n",
            "     4.13850218e-01  1.60760179e-01]\n",
            "   ...\n",
            "   [-1.26794803e+00  4.29791272e-01  2.93290466e-01 ...  6.52712941e-01\n",
            "     9.34922695e-03 -1.77564859e+00]\n",
            "   [ 2.72137928e+00  5.97640216e-01  1.00864685e+00 ...  5.01684010e-01\n",
            "     1.51797503e-01 -5.23506582e-01]\n",
            "   [-3.59835923e-01 -1.24471593e+00  3.38557065e-01 ...  9.64882076e-01\n",
            "    -8.83942306e-01  1.18420672e+00]]\n",
            "\n",
            "  [[ 1.15755737e+00 -2.47312859e-01 -1.85232544e+00 ...  5.41178048e-01\n",
            "     2.69179404e-01 -2.12892199e+00]\n",
            "   [-4.04597163e-01 -2.57741719e-01  1.39649844e+00 ... -6.92095280e-01\n",
            "    -3.76643211e-01  6.14588022e-01]\n",
            "   [-1.12125665e-01 -6.27754629e-02  1.99460149e-01 ... -1.53630793e-01\n",
            "     8.07094753e-01 -1.92743969e+00]\n",
            "   ...\n",
            "   [ 1.32602513e-01 -1.47106254e+00 -6.24156296e-01 ...  5.36897004e-01\n",
            "    -2.70121157e-01  2.03403091e+00]\n",
            "   [ 9.24762309e-01 -1.85752600e-01 -1.18417513e+00 ...  8.42486024e-01\n",
            "    -3.18040252e-01 -1.07377458e+00]\n",
            "   [ 1.14352334e+00 -7.45277464e-01 -2.25213468e-01 ...  4.57454294e-01\n",
            "     2.16585487e-01 -1.41202152e+00]]\n",
            "\n",
            "  [[ 7.50990883e-02 -5.98436356e-01 -1.48329449e+00 ...  4.51475352e-01\n",
            "     7.60144830e-01 -3.19927126e-01]\n",
            "   [-1.82309762e-01 -1.16222568e-01  1.95709419e+00 ...  1.95205069e+00\n",
            "    -1.08689092e-01 -9.51843485e-02]\n",
            "   [-1.32040334e+00  9.00417149e-01 -9.78961468e-01 ...  2.22621426e-01\n",
            "     8.86760950e-01  6.48341656e-01]\n",
            "   ...\n",
            "   [-2.74570727e+00 -8.45003247e-01 -1.37260365e+00 ...  1.10767055e+00\n",
            "    -1.17329276e+00 -1.60826743e-02]\n",
            "   [-1.55865267e-01  4.25075948e-01 -1.01304241e-01 ... -1.53018996e-01\n",
            "     2.40373150e-01 -1.24609792e+00]\n",
            "   [ 9.06710923e-01  3.46777856e-01  6.49032414e-01 ... -1.14091623e+00\n",
            "     1.50686979e+00 -3.76438498e-01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-1.29288599e-01 -1.57472491e+00  9.89304602e-01 ... -3.60855848e-01\n",
            "    -2.73271799e-01  3.20533782e-01]\n",
            "   [-1.43051326e+00  3.71524841e-01  1.40751183e+00 ... -1.37514031e+00\n",
            "     4.30730283e-01 -1.44469598e-02]\n",
            "   [-8.03784728e-01 -9.33080137e-01 -1.06044340e+00 ...  5.57150722e-01\n",
            "    -8.96310806e-01 -8.69103312e-01]\n",
            "   ...\n",
            "   [ 6.05903804e-01 -1.29434854e-01  1.73171115e+00 ...  5.18400311e-01\n",
            "     6.66001916e-01  9.52187657e-01]\n",
            "   [-7.38981605e-01 -1.41932261e+00 -1.27889082e-01 ... -2.40039897e+00\n",
            "     1.54742515e+00  2.94826180e-01]\n",
            "   [ 1.43925026e-01  1.89343441e+00 -5.01859546e-01 ... -1.21325187e-01\n",
            "     1.95011449e+00  6.77022040e-01]]\n",
            "\n",
            "  [[-3.78989018e-02  1.45952296e+00  1.37231007e-01 ...  1.13448215e+00\n",
            "     8.51578176e-01 -3.25813949e-01]\n",
            "   [-5.03580987e-01  4.48306024e-01 -1.62113905e+00 ... -4.19531800e-02\n",
            "     9.57807302e-01 -1.23828936e+00]\n",
            "   [ 1.33623183e-01 -9.17421460e-01 -3.88722956e-01 ... -9.53940153e-02\n",
            "     6.96426153e-01  5.40402770e-01]\n",
            "   ...\n",
            "   [ 2.64963359e-01  1.02650476e+00 -9.30566192e-01 ... -5.35343468e-01\n",
            "     5.39505661e-01  1.39707685e+00]\n",
            "   [ 8.43560323e-02  6.96693361e-01  1.11793339e+00 ... -1.05195470e-01\n",
            "     6.87259853e-01  1.11704636e+00]\n",
            "   [ 5.80528788e-02  2.87687480e-01 -5.26105285e-01 ...  2.68393219e-01\n",
            "     1.75509900e-01  1.30903733e+00]]\n",
            "\n",
            "  [[-7.22162664e-01 -8.55189979e-01  1.17101645e+00 ... -3.26562822e-01\n",
            "    -7.65250027e-01  1.56521797e-01]\n",
            "   [-2.70617306e-01  1.49871394e-01 -4.46972251e-01 ...  2.61885643e-01\n",
            "    -2.77973127e+00  9.40082908e-01]\n",
            "   [-1.97650388e-01  2.36485109e-01 -1.16407931e+00 ... -1.31271315e+00\n",
            "    -7.06119314e-02  2.19294101e-01]\n",
            "   ...\n",
            "   [-8.66508543e-01 -5.85344195e-01  6.95306182e-01 ... -1.01297766e-01\n",
            "    -1.74953043e-01  1.80564836e-01]\n",
            "   [-6.87604904e-01 -1.63580990e+00 -3.94631028e-01 ... -2.62516737e-02\n",
            "     1.17510200e+00  5.73430777e-01]\n",
            "   [ 1.10156476e+00  7.81318605e-01 -4.96649176e-01 ...  6.56586707e-01\n",
            "     1.32785693e-01 -5.63867867e-01]]]\n",
            "\n",
            "\n",
            " [[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 1.09306768e-01  2.30989531e-01  4.75664496e-01 ...  0.00000000e+00\n",
            "     1.76597796e-02  5.36545180e-02]\n",
            "   [ 6.76678345e-02  0.00000000e+00  2.96735823e-01 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 1.34836152e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  9.39819574e-01\n",
            "     4.14796323e-01  4.93613750e-01]\n",
            "   [ 1.07136771e-01  6.58050105e-02  5.93701489e-02 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  1.70240507e-01  3.66938449e-02 ...  0.00000000e+00\n",
            "     1.07312761e-03  0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  1.21143863e-01\n",
            "     2.10790902e-01  7.63924062e-01]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  8.82565081e-02\n",
            "     1.61629453e-01  8.80308688e-01]\n",
            "   [ 0.00000000e+00  0.00000000e+00  3.36348824e-02 ...  5.72974794e-02\n",
            "     9.07176435e-02  9.13817227e-01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  1.69395320e-02  1.90014288e-01 ...  4.20008786e-02\n",
            "     1.61995500e-01  4.87334013e-01]\n",
            "   [ 0.00000000e+00  1.11028776e-01  1.50374055e-01 ...  0.00000000e+00\n",
            "     0.00000000e+00  5.36987782e-01]\n",
            "   [ 0.00000000e+00  1.02750622e-02  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  6.36337578e-01]]\n",
            "\n",
            "  [[ 3.44447345e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 4.09223050e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 4.12221521e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 9.36113894e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 2.29563981e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 6.20371103e-03  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 8.48688841e-01  1.04722214e+00  1.82339084e+00 ...  1.88699734e+00\n",
            "     1.78527105e+00  1.47274399e+00]\n",
            "   [ 8.28944921e-01  7.08992779e-01  9.73672092e-01 ...  2.05221939e+00\n",
            "     1.93134701e+00  1.65001369e+00]\n",
            "   [ 8.12356293e-01  6.82989478e-01  7.76917875e-01 ...  1.97341835e+00\n",
            "     1.88207948e+00  1.65991700e+00]\n",
            "   ...\n",
            "   [ 8.60587239e-01  7.27488756e-01  8.29395473e-01 ...  1.64803183e+00\n",
            "     1.56652868e+00  1.28080237e+00]\n",
            "   [ 9.85202372e-01  7.45006263e-01  7.74209380e-01 ...  1.59061134e+00\n",
            "     1.64099538e+00  1.32343209e+00]\n",
            "   [ 7.99117029e-01  4.74449664e-01  4.86865163e-01 ...  1.20846570e+00\n",
            "     1.47726882e+00  1.26756585e+00]]]\n",
            "\n",
            "\n",
            " [[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 1.32990643e-01  7.69698024e-02  9.51224566e-02 ...  9.51033533e-02\n",
            "     7.95810670e-02  1.15766898e-01]\n",
            "   [ 2.90321223e-02  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 1.12519830e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  7.98326969e-01\n",
            "     0.00000000e+00  4.62768786e-02]\n",
            "   [ 0.00000000e+00  3.74483705e-01  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  2.02566497e-02]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  1.38172239e-01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.00000000e+00  2.96405964e-02  1.44429393e-02 ...  8.82935971e-02\n",
            "     9.61720347e-02  6.39754891e-01]\n",
            "   [ 0.00000000e+00  1.23267069e-01  9.84745175e-02 ...  6.65001869e-02\n",
            "     6.82331920e-02  6.18358910e-01]\n",
            "   [ 0.00000000e+00  5.75300716e-02  1.57959387e-01 ...  7.41978735e-02\n",
            "     8.28800946e-02  6.12118661e-01]\n",
            "   ...\n",
            "   [ 7.37294495e-01  2.61121917e+00  0.00000000e+00 ...  1.41656339e-01\n",
            "     6.30067289e-01  2.04137698e-01]\n",
            "   [ 8.38480473e-01  1.89150035e+00  0.00000000e+00 ...  2.35573910e-02\n",
            "     5.59035353e-02  1.39452457e-01]\n",
            "   [ 0.00000000e+00  3.34053934e-01  0.00000000e+00 ...  1.32942721e-01\n",
            "     1.15150839e-01  0.00000000e+00]]\n",
            "\n",
            "  [[ 3.62416834e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 7.13297129e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 1.77286908e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 1.38713539e+00  1.16876364e+00  1.16806448e+00 ...  1.26065290e+00\n",
            "     1.19724953e+00  1.06830776e+00]\n",
            "   [ 1.61144841e+00  1.35192025e+00  1.30363667e+00 ...  1.33994818e+00\n",
            "     1.27957571e+00  1.16314828e+00]\n",
            "   [ 1.58264077e+00  1.31449711e+00  1.24076521e+00 ...  1.36122763e+00\n",
            "     1.30748498e+00  1.16613519e+00]\n",
            "   ...\n",
            "   [ 3.08620191e+00  4.92124230e-01  3.12018299e+00 ...  5.46914756e-01\n",
            "     8.98870826e-02  2.45628968e-01]\n",
            "   [ 2.59899497e+00  8.09465051e-01  2.07623458e+00 ...  4.49811339e-01\n",
            "     4.71925884e-01  4.67663020e-01]\n",
            "   [ 1.48963869e+00  1.52758610e+00  1.69531047e+00 ...  2.27590665e-01\n",
            "     1.96365371e-01  1.62843004e-01]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 1.67717770e-01  4.99931872e-01  5.22344172e-01 ...  1.16698183e-01\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 1.27619848e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  2.33004555e-01]\n",
            "   [ 7.54132420e-02  0.00000000e+00  0.00000000e+00 ...  4.82563913e-01\n",
            "     5.65747678e-01  5.33353925e-01]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  4.71442372e-01\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.00000000e+00  3.86430204e-01  4.06365782e-01 ...  0.00000000e+00\n",
            "     1.39651909e-01  1.41030765e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  2.38270089e-01 ...  0.00000000e+00\n",
            "     9.42726061e-03  1.16851163e+00]\n",
            "   [ 0.00000000e+00  2.12278925e-02  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  1.76054752e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  2.29278319e-02 ...  9.85533297e-02\n",
            "     1.41806141e-01  5.33980548e-01]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  7.82869607e-02\n",
            "     2.19297841e-01  3.56119126e-01]\n",
            "   [ 0.00000000e+00  6.85127228e-02  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  5.90933859e-01]]\n",
            "\n",
            "  [[ 3.40819687e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 4.80940729e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 4.05531198e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 3.18606049e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 2.79706061e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 5.90586029e-02  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 1.93364251e+00  1.54029512e+00  8.00991356e-01 ...  2.74939942e+00\n",
            "     2.45957565e+00  2.23169374e+00]\n",
            "   [ 2.01261306e+00  1.76599491e+00  1.79688525e+00 ...  3.00025058e+00\n",
            "     2.77723026e+00  2.51098704e+00]\n",
            "   [ 2.00601983e+00  1.72161627e+00  1.71489954e+00 ...  2.88325763e+00\n",
            "     3.55140042e+00  3.10172200e+00]\n",
            "   ...\n",
            "   [ 2.55772519e+00  2.21349573e+00  2.23000407e+00 ...  1.15546143e+00\n",
            "     1.01798153e+00  8.86526108e-01]\n",
            "   [ 2.63625693e+00  2.26506782e+00  2.30643487e+00 ...  1.09423232e+00\n",
            "     9.93523419e-01  5.39390624e-01]\n",
            "   [ 2.33841348e+00  1.97055256e+00  1.94349349e+00 ...  7.86869586e-01\n",
            "     7.96493828e-01  9.24230993e-01]]]\n",
            "\n",
            "\n",
            " [[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 1.40511647e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 2.63454318e-02  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 5.24581932e-02  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     1.72525138e-01  0.00000000e+00]\n",
            "   ...\n",
            "   [ 3.35614115e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 8.04921836e-02  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  2.93287694e-01\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  6.00057781e-01\n",
            "     0.00000000e+00  1.55368185e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  4.98045623e-01\n",
            "     0.00000000e+00  1.58697414e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  4.57317948e-01\n",
            "     0.00000000e+00  1.64150918e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  1.09480992e-01 ...  0.00000000e+00\n",
            "     5.58265559e-02  1.32757032e+00]\n",
            "   [ 0.00000000e+00  1.56255476e-02  1.85472034e-02 ...  0.00000000e+00\n",
            "     0.00000000e+00  1.22901356e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  8.66998136e-01]]\n",
            "\n",
            "  [[ 2.80724078e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 3.86931926e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 3.53392631e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 5.78182459e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 5.45604765e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 2.73141950e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 1.25638831e+00  1.14904761e+00  1.18527412e+00 ...  2.61079001e+00\n",
            "     3.17166758e+00  2.34695148e+00]\n",
            "   [ 1.36137354e+00  1.23297250e+00  1.37031865e+00 ...  2.89683580e+00\n",
            "     3.81923032e+00  2.68723059e+00]\n",
            "   [ 1.37258971e+00  1.25296807e+00  1.43633866e+00 ...  2.90289211e+00\n",
            "     3.53018117e+00  2.41715717e+00]\n",
            "   ...\n",
            "   [ 1.56781650e+00  1.39562738e+00  1.46796429e+00 ...  2.94197392e+00\n",
            "     2.82980108e+00  2.70915437e+00]\n",
            "   [ 1.50445259e+00  1.29969668e+00  1.31047618e+00 ...  2.69409513e+00\n",
            "     2.75235510e+00  2.54778767e+00]\n",
            "   [ 1.32177329e+00  1.11204994e+00  1.15141666e+00 ...  1.67808676e+00\n",
            "     2.19004083e+00  2.03125954e+00]]]\n",
            "\n",
            "\n",
            " [[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 4.96233515e-02  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     7.48523176e-01  6.63338542e-01]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  9.03173208e-01\n",
            "     0.00000000e+00  5.99339865e-02]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  8.76614749e-02]\n",
            "   ...\n",
            "   [ 1.16550200e-01  5.82583129e-01  3.01906496e-01 ...  2.07085565e-01\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 4.80068624e-02  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.00000000e+00  8.15744549e-02  1.60734907e-01 ...  7.25675344e-01\n",
            "     7.13587582e-01  9.54755992e-02]\n",
            "   [ 0.00000000e+00  5.94026856e-02  1.42689422e-01 ...  6.53434575e-01\n",
            "     0.00000000e+00  8.10558379e-01]\n",
            "   [ 0.00000000e+00  1.77660249e-02  1.11615106e-01 ...  0.00000000e+00\n",
            "     3.51148427e-01  7.02595413e-01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  2.11206488e-02 ...  0.00000000e+00\n",
            "     2.41296999e-02  5.33164501e-01]\n",
            "   [ 0.00000000e+00  6.14081137e-02  6.15509860e-02 ...  0.00000000e+00\n",
            "     1.09378062e-02  5.21023393e-01]\n",
            "   [ 0.00000000e+00  0.00000000e+00  2.42209658e-02 ...  0.00000000e+00\n",
            "     3.98132950e-03  4.97121513e-01]]\n",
            "\n",
            "  [[ 2.67153323e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 2.92022228e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 2.90117651e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 4.22213137e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 1.52112812e-01  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]\n",
            "   [ 7.95506313e-03  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "     0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 1.33571804e+00  1.11536586e+00  1.05521107e+00 ...  1.37404788e+00\n",
            "     9.29724157e-01  6.71810567e-01]\n",
            "   [ 1.56881535e+00  1.31926358e+00  1.28065801e+00 ...  1.19088590e+00\n",
            "     5.22543192e-01  6.10554874e-01]\n",
            "   [ 1.65667427e+00  1.41626549e+00  1.38976884e+00 ...  8.08000028e-01\n",
            "     1.14675081e+00  6.25094652e-01]\n",
            "   ...\n",
            "   [ 1.51019073e+00  1.23125398e+00  9.69132602e-01 ...  1.72848213e+00\n",
            "     1.46415353e+00  1.32558870e+00]\n",
            "   [ 1.16180170e+00  9.92310882e-01  9.56599712e-01 ...  1.35225785e+00\n",
            "     1.41495216e+00  1.31187165e+00]\n",
            "   [ 9.79821265e-01  8.81311595e-01  8.92443597e-01 ...  1.19753563e+00\n",
            "     1.23929584e+00  1.15066016e+00]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahEfLpznITlQ",
        "outputId": "acc699f4-d11e-4c8b-8854-43b075416256"
      },
      "source": [
        "print('embedding shape:', embedding.shape)\n",
        "last_img_embedding = embedding[7500:, :, :, ]\n",
        "print('\\n embedding shape of the last image for instance:', last_img_embedding.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedding shape: torch.Size([7501, 256, 16, 16])\n",
            "\n",
            " embedding shape of the last image for instance: torch.Size([1, 256, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1z3KUOyHkCu"
      },
      "source": [
        "def find_similar_images(test_image, num_sim_images, embedding, device):\n",
        "    \"\"\"\n",
        "    Searches for a similar image given an image and number of similar images to search.\n",
        "    :param image: Image whose similar images need to be found\n",
        "    :param num_sim_images: Number of similar images to find (K argument in K-Nearest Neighbors algorithm)\n",
        "    :param embedding: A (num_sim_images, embedding_dim) embedding of images learnt from auto-encoder.\n",
        "    :param device: \"cuda\" or \"cpu\" device\n",
        "    :returns: the indices of similar image to the test image\n",
        "    \"\"\"\n",
        "\n",
        "    image_tensor = T.ToTensor()(test_image)\n",
        "    image_tensor = image_tensor.unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        # the test image whose similar images are required need to be converted to feature representation\n",
        "        # This line raised error as the model is on GPU, but data is on the CPU. So, we need to send our image tensor to GPU\n",
        "\n",
        "        #image_embedding = encoder(image_tensor).cpu().detach().numpy()\n",
        "        image_embedding = encoder(image_tensor.to(device)).detach().numpy()\n",
        "        print('image_embedding:', image_embedding)\n",
        "    flattened_embedding = image_embedding.reshape((image_embedding.shape[0], -1))\n",
        "    print(flattened_embedding)\n",
        "    knn = NearestNeighbors(n_neighbors=num_sim_images, metric=\"cosine\")\n",
        "    knn.fit(embedding)\n",
        "    _, indices = knn.kneighbors(flattened_embedding)\n",
        "    return indices.tolist()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7DpH0bkhVIv"
      },
      "source": [
        "Test_iamge_path = \"/content/drive/MyDrive/test/\"\n",
        "num_sim_images = 1\n",
        "encode_model_path = \"/content/encoder_model.pt\"\n",
        "embedding_path = \"/content/data_embedding.npy\"\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "encoder = ConvEncoder()\n",
        "# Load the state dict of encoder\n",
        "encoder.load_state_dict(torch.load(encode_model_path, map_location=device))\n",
        "encoder.eval()\n",
        "encoder.to(device)\n",
        "\n",
        "# Loads the embedding\n",
        "embedding = np.load(embedding_path)\n",
        "for test_image in test_df['id']:\n",
        "  test_image = Image.open(Test_iamge_path + test_image + '.jpg').convert(\"RGB\")\n",
        "  indices_list = find_similar_images(test_image, num_sim_images, embedding, device)\n",
        "  print(indices_list)\n",
        "  #plot_similar_images(indices_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWKppZtagbyu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}