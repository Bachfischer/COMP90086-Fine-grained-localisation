{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "import operator\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG4287_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG4288_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG4289_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG4290_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG4291_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>IMG5482_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>IMG5483_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>IMG5484_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>IMG5485_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>IMG5486_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id\n",
       "0     IMG4287_3\n",
       "1     IMG4288_5\n",
       "2     IMG4289_5\n",
       "3     IMG4290_4\n",
       "4     IMG4291_5\n",
       "...         ...\n",
       "1195  IMG5482_1\n",
       "1196  IMG5483_2\n",
       "1197  IMG5484_4\n",
       "1198  IMG5485_3\n",
       "1199  IMG5486_2\n",
       "\n",
       "[1200 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./train/train.csv\")\n",
    "test_df = pd.read_csv(\"./test/imagenames.csv\")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best match: ('IMG4287_3', 'IMG3442_3', 83)\n",
      "Best match: ('IMG4288_5', 'IMG2755_2', 68)\n",
      "Best match: ('IMG4289_5', 'IMG3018_5', 48)\n",
      "Best match: ('IMG4290_4', 'IMG3858_3', 12)\n",
      "Best match: ('IMG4291_5', 'IMG3207_1', 45)\n",
      "Best match: ('IMG4292_3', 'IMG3855_1', 35)\n",
      "Best match: ('IMG4293_3', 'IMG2899_5', 12)\n",
      "Best match: ('IMG4294_1', 'IMG3713_1', 36)\n",
      "Best match: ('IMG4295_1', 'IMG2815_1', 164)\n",
      "Best match: ('IMG4296_1', 'IMG3785_5', 176)\n",
      "Best match: ('IMG4297_4', 'IMG2831_3', 7)\n",
      "Best match: ('IMG4298_1', 'IMG2902_3', 40)\n",
      "Best match: ('IMG4299_3', 'IMG3240_3', 24)\n",
      "Best match: ('IMG4300_5', 'IMG3043_1', 29)\n",
      "Best match: ('IMG4301_3', 'IMG3367_5', 5)\n",
      "Best match: ('IMG4302_2', 'IMG3431_2', 38)\n",
      "Best match: ('IMG4303_2', 'IMG3473_5', 73)\n",
      "Best match: ('IMG4304_5', 'IMG3242_5', 35)\n",
      "Best match: ('IMG4305_5', 'IMG3363_2', 127)\n",
      "Best match: ('IMG4306_4', 'IMG3071_3', 30)\n",
      "Best match: ('IMG4307_4', 'IMG4154_4', 39)\n",
      "Best match: ('IMG4308_3', 'IMG4101_3', 138)\n",
      "Best match: ('IMG4309_1', 'IMG3367_3', 127)\n",
      "Best match: ('IMG4310_4', 'IMG3266_5', 53)\n",
      "Best match: ('IMG4311_4', 'IMG3412_4', 52)\n",
      "Best match: ('IMG4312_2', 'IMG2805_1', 173)\n",
      "Best match: ('IMG4313_3', 'IMG3988_3', 45)\n",
      "Best match: ('IMG4314_5', 'IMG3762_1', 22)\n",
      "Best match: ('IMG4315_5', 'IMG3064_3', 190)\n",
      "Best match: ('IMG4316_2', 'IMG2934_4', 44)\n",
      "Best match: ('IMG4318_2', 'IMG3931_2', 76)\n",
      "Best match: ('IMG4319_2', 'IMG3697_1', 23)\n",
      "Best match: ('IMG4320_2', 'IMG3020_2', 136)\n",
      "Best match: ('IMG4321_5', 'IMG3512_2', 38)\n",
      "Best match: ('IMG4322_4', 'IMG3988_3', 64)\n",
      "Best match: ('IMG4323_2', 'IMG3620_4', 20)\n",
      "Best match: ('IMG4324_5', 'IMG3700_3', 95)\n",
      "Best match: ('IMG4325_4', 'IMG3816_2', 98)\n",
      "Best match: ('IMG4326_5', 'IMG2867_5', 46)\n",
      "Best match: ('IMG4327_4', 'IMG2867_2', 42)\n",
      "Best match: ('IMG4328_4', 'IMG4096_3', 7)\n",
      "Best match: ('IMG4329_1', 'IMG3072_5', 20)\n",
      "Best match: ('IMG4330_4', 'IMG3016_2', 188)\n",
      "Best match: ('IMG4331_2', 'IMG3363_2', 118)\n",
      "Best match: ('IMG4332_3', 'IMG3783_1', 76)\n",
      "Best match: ('IMG4333_2', 'IMG3578_5', 58)\n",
      "Best match: ('IMG4334_3', 'IMG3544_5', 18)\n",
      "Best match: ('IMG4335_4', 'IMG3352_4', 63)\n",
      "Best match: ('IMG4336_4', 'IMG3110_5', 92)\n",
      "Best match: ('IMG4337_2', 'IMG2757_3', 60)\n",
      "Best match: ('IMG4338_3', 'IMG3313_3', 84)\n",
      "Best match: ('IMG4339_5', 'IMG2860_4', 154)\n",
      "Best match: ('IMG4340_4', 'IMG3529_5', 219)\n",
      "Best match: ('IMG4341_5', 'IMG3509_2', 60)\n",
      "Best match: ('IMG4342_5', 'IMG3485_2', 83)\n",
      "Best match: ('IMG4343_5', 'IMG3367_5', 103)\n",
      "Best match: ('IMG4344_5', 'IMG3153_2', 15)\n",
      "Best match: ('IMG4345_3', 'IMG3430_5', 380)\n",
      "Best match: ('IMG4346_3', 'IMG4216_4', 68)\n",
      "Best match: ('IMG4347_5', 'IMG3722_1', 34)\n",
      "Best match: ('IMG4348_5', 'IMG3843_2', 94)\n",
      "Best match: ('IMG4349_5', 'IMG3748_1', 83)\n"
     ]
    }
   ],
   "source": [
    "min_match_count = 4\n",
    "ratio = 0.6\n",
    "image_path_test = './test/'\n",
    "image_path_train = './train/'\n",
    "all_test_images = []\n",
    "\n",
    "# Initiate SIFT detector\n",
    "sift_obj = cv2.SIFT_create()\n",
    "for test_img_id in test_df['id']:\n",
    "    test_image = cv2.imread(os.path.join(image_path_test + test_img_id + '.jpg'), cv2.IMREAD_GRAYSCALE)\n",
    "    # Compute SIFT keypoints and descriptors\n",
    "    kp_test, des_test = sift_obj.detectAndCompute(test_image, None)\n",
    "    # FLANN parameters and initialize\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks=50)   \n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    all_successes = []\n",
    "    for train_img_id in train_df['id']:\n",
    "        matchesMask = []\n",
    "        train_image = cv2.imread(os.path.join(image_path_train + train_img_id + '.jpg'), cv2.IMREAD_GRAYSCALE)\n",
    "        # Compute SIFT keypoints and descriptors for the test set\n",
    "        kp_train, des_train = sift_obj.detectAndCompute(train_image, None)\n",
    "        # Matching descriptor using KNN algorithm\n",
    "        # Exclude images for which SIFT could not detectAndCompute any descriptors\n",
    "        if (des_test is not None) and (des_train is not None):\n",
    "            matches = flann.knnMatch(des_train, des_test, k=2)\n",
    "            # keeps a list of good matches\n",
    "            goodMatches = [] \n",
    "            for nearest_neighb, second_nearest_neighb in matches:\n",
    "                # Check the distance ratio between the 1st nearest neighbor and 2nd nearest neighbour\n",
    "                # Lowe’s ratio test to increase the robustness of the SIFT algorithm and to remove points that are not distinct enough. \n",
    "                if nearest_neighb.distance < ratio * second_nearest_neighb.distance:\n",
    "                    goodMatches.append(nearest_neighb)\n",
    "                \n",
    "        if (len(goodMatches) >= min_match_count):\n",
    "            # Estimate homography between two images\n",
    "            keypts_train_img = np.zeros((len(goodMatches), 2), dtype=np.float32)\n",
    "            keypts_test_img = np.zeros((len(goodMatches), 2), dtype=np.float32)\n",
    "            # Exclude images for which SIFT could not detectAndCompute any keypoints\n",
    "            if (len(kp_test) != 0) and ((len(kp_train) != 0)):\n",
    "                keypts_train_img = np.float32([kp_train[match.queryIdx].pt for match in goodMatches]).reshape(-1,1,2)\n",
    "                keypts_test_img = np.float32([kp_test[match.trainIdx].pt for match in goodMatches]).reshape(-1,1,2)\n",
    "                # status returns a list of feature points that represent successful matches\n",
    "                # May require changing the ratio used in the Lowe's ratio test of FLANN matcher and/or the maxIters parameter of the RANSAC\n",
    "                H, status = cv2.findHomography(keypts_train_img, keypts_test_img, cv2.RANSAC, ransacReprojThreshold = 5, maxIters = 500)\n",
    "                success = status.ravel().tolist()\n",
    "                if (success.count(1) > 0):\n",
    "#                     draw_params = dict(matchColor = (0,255,0), singlePointColor = (255,0,0), matchesMask = success, flags = 2)\n",
    "#                     success_matches = cv2.drawMatches(train_image, kp_train, test_image, kp_test, goodMatches, None, **draw_params)\n",
    "                    all_successes.append((test_img_id, train_img_id, success.count(1))) #, success_matches\n",
    "                else:\n",
    "                    success = 0\n",
    "            else:\n",
    "                success = 0\n",
    "        # Find the best matched image which has the largest success    \n",
    "    all_successes.sort(key = operator.itemgetter(2), reverse = True)\n",
    "    test_img_dict = {}\n",
    "    if len(all_successes) > 0:\n",
    "        # Find the ID of best matched image\n",
    "        best_match = all_successes[0]\n",
    "        print('Best match:', best_match)\n",
    "        x_coordiante = train_df[train_df['id'] == best_match[1]]['x']\n",
    "        y_coordinate = train_df[train_df['id'] == best_match[1]]['y']\n",
    "        test_img_dict = {'id': best_match[0], 'x': list(x_coordiante)[0] , 'y': list(y_coordinate)[0]}\n",
    "        #print(test_img_dict)\n",
    "        # Plotting results\n",
    "#         for match in best_matches:\n",
    "#             plt.imshow(match[2])\n",
    "#             plt.axis('off')\n",
    "#             plt.show()\n",
    "    all_test_images.append(test_img_dict)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
